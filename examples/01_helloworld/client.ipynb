{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/mnt/shared_disk/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create server parameters for stdio connection\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    # Make sure to update to the full absolute path to your math_server.py file\n",
    "    args=[\"/home/bws/xm2025/git2025/langchian_test/examples/01_helloworld/server.py\"],\n",
    ")\n",
    "\n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # Initialize the connection\n",
    "        await session.initialize()\n",
    "\n",
    "        # Get tools\n",
    "        tools = await load_mcp_tools(session)\n",
    "\n",
    "        # Create and run the agent\n",
    "        agent = create_react_agent(model, tools)\n",
    "        agent_response = await agent.ainvoke({\"messages\": \"what's (3 + 5) x 12?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's (3 + 5) x 12?\", additional_kwargs={}, response_metadata={}, id='da7c7bc1-4d63-437a-a109-e31253946835'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_F8LWzC0Unw6VMIZVZ6uV1OkP', 'function': {'arguments': '{\"a\":3,\"b\":5}', 'name': 'add'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 77, 'total_tokens': 94, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'openai/gpt-4o', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a81bada0-8f28-4794-9a46-600d5a8842c6-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_F8LWzC0Unw6VMIZVZ6uV1OkP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 77, 'output_tokens': 17, 'total_tokens': 94, 'input_token_details': {}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='8', name='add', id='d2a38363-b3bf-4711-8318-6bbb0271d49e', tool_call_id='call_F8LWzC0Unw6VMIZVZ6uV1OkP'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_RSfE5CPesiq9QrWkWALiCdcW', 'function': {'arguments': '{\"a\":8,\"b\":12}', 'name': 'multiply'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 102, 'total_tokens': 119, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'openai/gpt-4o', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6f1590c9-4848-42cb-8bdc-56affd713fba-0', tool_calls=[{'name': 'multiply', 'args': {'a': 8, 'b': 12}, 'id': 'call_RSfE5CPesiq9QrWkWALiCdcW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 102, 'output_tokens': 17, 'total_tokens': 119, 'input_token_details': {}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='96', name='multiply', id='9401858a-7494-4ee9-a132-6d7b52369eaa', tool_call_id='call_RSfE5CPesiq9QrWkWALiCdcW'),\n",
       "  AIMessage(content='The result of (3 + 5) x 12 is 96.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 127, 'total_tokens': 144, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'openai/gpt-4o', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-11c49f63-061a-41a4-b85d-1bd1b708b739-0', usage_metadata={'input_tokens': 127, 'output_tokens': 17, 'total_tokens': 144, 'input_token_details': {}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/bws/miniconda3/envs/langgraph/lib/python3.12/site-packages/mcp/client/sse.py\", line 53, in sse_client\n",
      "    event_source.response.raise_for_status()\n",
      "  File \"/home/bws/miniconda3/envs/langgraph/lib/python3.12/site-packages/httpx/_models.py\", line 829, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Server error '502 Bad Gateway' for url 'http://localhost:8000/sse'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/home/bws/miniconda3/envs/langgraph/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3547, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"/tmp/ipykernel_1068240/2394221810.py\", line 7, in <module>\n",
      "  |     async with MultiServerMCPClient(\n",
      "  |                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/bws/miniconda3/envs/langgraph/lib/python3.12/site-packages/langchain_mcp_adapters/client.py\", line 223, in __aenter__\n",
      "  |     await self.connect_to_server_via_sse(server_name, **connection_dict)\n",
      "  |   File \"/home/bws/miniconda3/envs/langgraph/lib/python3.12/site-packages/langchain_mcp_adapters/client.py\", line 198, in connect_to_server_via_sse\n",
      "  |     sse_transport = await self.exit_stack.enter_async_context(sse_client(url))\n",
      "  |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/bws/miniconda3/envs/langgraph/lib/python3.12/contextlib.py\", line 659, in enter_async_context\n",
      "  |     result = await _enter(cm)\n",
      "  |              ^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/bws/miniconda3/envs/langgraph/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "  |     return await anext(self.gen)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/bws/miniconda3/envs/langgraph/lib/python3.12/site-packages/mcp/client/sse.py\", line 43, in sse_client\n",
      "  |     async with anyio.create_task_group() as tg:\n",
      "  |                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/bws/miniconda3/envs/langgraph/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/home/bws/miniconda3/envs/langgraph/lib/python3.12/site-packages/mcp/client/sse.py\", line 53, in sse_client\n",
      "    |     event_source.response.raise_for_status()\n",
      "    |   File \"/home/bws/miniconda3/envs/langgraph/lib/python3.12/site-packages/httpx/_models.py\", line 829, in raise_for_status\n",
      "    |     raise HTTPStatusError(message, request=request, response=self)\n",
      "    | httpx.HTTPStatusError: Server error '502 Bad Gateway' for url 'http://localhost:8000/sse'\n",
      "    | For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n",
      "    +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"math\": {\n",
    "            \"command\": \"python\",\n",
    "            # Make sure to update to the full absolute path to your math_server.py file\n",
    "            \"args\": [\"/home/bws/xm2025/git2025/langchian_test/examples/01_helloworld/server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        \"weather\": {\n",
    "            # make sure you start your weather server on port 8000\n",
    "            \"url\": \"http://172.28.140.214:8000/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    agent = create_react_agent(model, client.get_tools())\n",
    "    # math_response = await agent.ainvoke({\"messages\": \"what's (3 + 5) x 12?\"})\n",
    "    weather_response = await agent.ainvoke({\"messages\": \"what is the weather in nyc?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
